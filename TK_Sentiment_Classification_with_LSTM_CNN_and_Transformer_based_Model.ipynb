{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLNg_Puse6EX"
   },
   "source": [
    "# Text Classification for the IMDB Dataset using DL\n",
    "**Objective:** classify the IMDB Reviews into positive or negative. <br>\n",
    "In this notebook we explore different DL-based text classification models and compare their performance. <br>\n",
    "The notebook is coded with Keras and explores the following three architectures:\n",
    "1. CNN-based models with and without pre-trained embeddings\n",
    "2. LSTM-based models with and without pre-trained embeddings\n",
    "3. Transformer-based models with and without pre-trained embeddings (for you to do)\n",
    "This notebook needs a GPU; google colab could be used.\n",
    "**Useful documentation** <br>\n",
    "- [Pre-trained embeddings with Keras](https://keras.io/examples/nlp/pretrained_word_embeddings/) \n",
    "- [Sentiment classification with LSTM keras](https://slundberg.github.io/shap/notebooks/deep_explainer/Keras%20LSTM%20for%20IMDB%20Sentiment%20Classification.html) \n",
    "# Installation of needed libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUL_X6mjrvSS"
   },
   "source": [
    "# Importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xqUcb7NBb5--"
   },
   "outputs": [],
   "source": [
    "import os, sys, numpy as np, pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZLq2c-1r0kj"
   },
   "source": [
    "# Downloading dataset & pre-trained GLOVE embeddings\n",
    "1. [GLOVE](http://nlp.stanford.edu/data/glove.6B.zip)\n",
    "2. [IMDB dataset](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)\n",
    "\n",
    "They are both zipped, thus we need to unzip them. <br>\n",
    "We will put the data and pre-trained mebddings into a folder called Data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JIP7bJ5W1Rzo",
    "outputId": "b6e46e78-7d21-4d5e-a260-be1782ff4bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mount your Google Drive to Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RP-kcjBC3sC5",
    "outputId": "9189e842-bc8c-4984-9c0c-ee3b5aa9ae4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "drive.mount(\"/content/gdrive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "t941jNzy5J7Q",
    "outputId": "c8f066f8-a55d-4929-a42b-ff88bba97073"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TBYiQcMU3unO"
   },
   "outputs": [],
   "source": [
    "GLOVE_DIR = \"/content/gdrive/MyDrive/Homeworks pt 2/LSTM HWK/glove\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "33IKSocHxcSS",
    "outputId": "78339d92-505b-4693-f07e-a9c555174b43"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/gdrive/MyDrive/Homeworks pt 2/LSTM HWK/glove'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GLOVE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ej7Qz8lZ5PCs"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_excel('/content/gdrive/MyDrive/Homeworks pt 2/LSTM HWK/train_set_imdb_reviews.xlsx')\n",
    "df_test = pd.read_excel('/content/gdrive/MyDrive/Homeworks pt 2/LSTM HWK/test_set_imdb_reviews.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-KXfze1gxcSU",
    "outputId": "d5d2c6e3-88eb-4230-9772-cbbd72b7c37e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bd485dc5-539b-4e98-ae20-9bd4bac4fe2a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I am amazed at how this movie(and most others ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd485dc5-539b-4e98-ae20-9bd4bac4fe2a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bd485dc5-539b-4e98-ae20-9bd4bac4fe2a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bd485dc5-539b-4e98-ae20-9bd4bac4fe2a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                 reviews  sentiment\n",
       "0      Story of a man who has unnatural feelings for ...          0\n",
       "1      Airport '77 starts as a brand new luxury 747 p...          0\n",
       "2      This film lacked something I couldn't put my f...          0\n",
       "3      Sorry everyone,,, I know this is supposed to b...          0\n",
       "4      When I was little my parents took me along to ...          0\n",
       "...                                                  ...        ...\n",
       "24995  Seeing as the vote average was pretty low, and...          1\n",
       "24996  The plot had some wretched, unbelievable twist...          1\n",
       "24997  I am amazed at how this movie(and most others ...          1\n",
       "24998  A Christmas Together actually came before my t...          1\n",
       "24999  Working-class romantic drama from director Mar...          1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "HCwg_BxLxcSU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "XzZp0uB0xcSU",
    "outputId": "3667c848-7f12-422a-8add-4b2b15fcb67b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bf5a73a7-e3b5-4f2c-b19b-52b7d8165655\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>I was extraordinarily impressed by this film. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Although I'm not a golf fan, I attended a snea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>From the start of \"The Edge Of Love\", the view...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>This movie, with all its complexity and subtle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>I've seen this story before but my kids haven'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf5a73a7-e3b5-4f2c-b19b-52b7d8165655')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bf5a73a7-e3b5-4f2c-b19b-52b7d8165655 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bf5a73a7-e3b5-4f2c-b19b-52b7d8165655');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                 reviews  sentiment\n",
       "0      Once again Mr. Costner has dragged out a movie...          0\n",
       "1      This is an example of why the majority of acti...          0\n",
       "2      First of all I hate those moronic rappers, who...          0\n",
       "3      Not even the Beatles could write songs everyon...          0\n",
       "4      Brass pictures (movies is not a fitting word f...          0\n",
       "...                                                  ...        ...\n",
       "24995  I was extraordinarily impressed by this film. ...          1\n",
       "24996  Although I'm not a golf fan, I attended a snea...          1\n",
       "24997  From the start of \"The Edge Of Love\", the view...          1\n",
       "24998  This movie, with all its complexity and subtle...          1\n",
       "24999  I've seen this story before but my kids haven'...          1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUYxHxtExcSV"
   },
   "source": [
    "# EDA\n",
    "- Explore both datasets\n",
    "- Clean the datasets: !!! The cleaning steps should be deduced following the exploration done on the train set not on the test set to garantee **no data leakage**. However, it is applied on both. \n",
    "- Check if the dataset is balanced or not \n",
    "- Bonus: fix the imbalance if it turns out to be the case\n",
    "\n",
    "At the end of the EDA, set the cleaned reviews (texts) to the variables ``train_texts`` and ``test_texts`` and the sentiments to ``train_labels`` and ``test_labels``. <br>\n",
    "If you failed this step, use the following commands: <br>\n",
    "1. ``train_texts = df_train.reviews.apply(lambda x: str(x)).tolist()``\n",
    "2. ``test_texts = df_train.reviews.apply(lambda x: str(x)).tolist()``\n",
    "3. ``train_labels = df_train.sentiment.tolist()``\n",
    "4. ``test_labels = df_test.sentiment.tolist()``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvHtmMP5xcSV"
   },
   "source": [
    "## Explore Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOxCEyT-xcSV"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrvwdF1dxcSV"
   },
   "source": [
    "#### Distribution of sentiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJSrijqPxcSW",
    "outputId": "41a08870-f206-44df-ee39-a6cafcbfd013"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4LHCdN3xcSW",
    "outputId": "756cde12-1d52-4844-863f-a07c0a46009f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews      0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "1PbU8bf4xcSW",
    "outputId": "b8e94e57-f5ca-411c-d0dd-d09ebc9f86a8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of reviews in each sentiment category\n",
    "sentiment_counts = df_train['sentiment'].value_counts()\n",
    "\n",
    "# Visualize the distribution of sentiments using a bar chart\n",
    "sentiment_counts.plot(kind='bar')\n",
    "plt.title('Distribution of Sentiments')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3yw1MZ5ExcSW",
    "outputId": "0a38b761-2043-44be-d3b4-7c733c4cc54f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12500\n",
       "1    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this graph I could verify that there the sentiment column in the train set was balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYQW260YxcSX"
   },
   "source": [
    "#### Checking for missing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dN7fwQSexcSX",
    "outputId": "85b206f6-2a9f-4ea7-ac1c-22fe4510dd6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3504 does not contain text\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_train.iterrows():\n",
    "    if isinstance(row['reviews'], str) and len(row['reviews']) > 0:\n",
    "       pass\n",
    "    else:\n",
    "        print('Row {} does not contain text'.format(index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12FtcdVjxcSX",
    "outputId": "d90eeac5-04dd-43a0-e6d0-0cbc66f60d26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.reviews[3504]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fu6khvUcxcSX",
    "outputId": "55e41a9f-4c21-411b-f2bf-3db3a8051632"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sentiment[3504]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "N4huuMpbxcSY"
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(df_train.index[3504])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to check whether there were any rows that didn't contain actual text, but was not considered aa \"missing value\" - I found the row using a forloop, and chose to drop it to keep the data consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bs309Vm8xcSY"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2o_blGR4xcSY",
    "outputId": "845e7082-873d-4afb-aa5d-a6e7d9213630"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2KGNdCQxcSY",
    "outputId": "0d1520c3-f152-4ca2-ae19-c475407faa6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews      0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9Spr0ODxcSY"
   },
   "source": [
    "#### Distribution of Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "9W6OmweNxcSY",
    "outputId": "4374925c-a9a7-427a-db5f-e4f895a44e64"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of reviews in each sentiment category\n",
    "sentiment_counts = df_test['sentiment'].value_counts()\n",
    "\n",
    "# Visualize the distribution of sentiments using a bar chart\n",
    "sentiment_counts.plot(kind='bar')\n",
    "plt.title('Distribution of Sentiments')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this graph I could verify that there the sentiment column in the test set was balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yy_6NOpTxcSZ"
   },
   "source": [
    "#### Checking for missing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PEi8_5PIxcSZ",
    "outputId": "6432209b-66a8-44e2-93f6-b81c6c008d88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2950 does not contain text\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_test.iterrows():\n",
    "    if isinstance(row['reviews'], str) and len(row['reviews']) > 0:\n",
    "       pass\n",
    "    else:\n",
    "        print('Row {} does not contain text'.format(index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SRzsk5FhxcSZ",
    "outputId": "71e1910a-3ca3-44d0-aa71-abbdd604ce17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.reviews[2950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wiZDISKJxcSZ",
    "outputId": "f1dd4d5c-8a28-4314-91c2-58f6535bfc6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sentiment[2950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "tlKceZ5FxcSa"
   },
   "outputs": [],
   "source": [
    "df_test = df_test.drop(df_test.index[3504])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also found that there was a row in the test set that also didn't contain proper text, I dropped this row as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thktlYOoxcSa"
   },
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhTSc4QrxcSa",
    "outputId": "a7e5c338-f720-4bda-afad-4a3c6b7b170c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess(text):\n",
    "    # Remove HTML tags\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    # Remove punctuation marks\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining my Function\n",
    "\n",
    "My preprocessing function is used for the \"reviews\" column of the dataset, to carry out the following actions: \n",
    "\n",
    "- Removes any HTML tags from the text using the BeautifulSoup library.\n",
    "- Converts all the text to lowercase using the lower() method.\n",
    "- Removes any digits from the text using the regular expression \\d+.\n",
    "- Removes any stopwords from the text using the NLTK library.\n",
    "- Removes any punctuation marks from the text using the regular expression [^\\w\\s].\n",
    "- Lemmatizes the words in the text using the WordNetLemmatizer from the NLTK library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hj-Oc_mJxcSb"
   },
   "source": [
    "#### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FpzgfTwGxcSb",
    "outputId": "de41751f-25a1-4cd3-a9fa-a47dda075072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df_train['reviews'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "NbkQhxehxcSb"
   },
   "outputs": [],
   "source": [
    "df_train['reviews'] = df_train['reviews'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMaD3e3IxcSb",
    "outputId": "776133e9-1881-44e7-9bc7-cec757c40b74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df_train['reviews'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3OO1wbh5xcSc",
    "outputId": "ba80ff7f-e8be-4d57-8dfe-2dc5f802030a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-681b20c3b033>:12: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "df_train['clean_reviews'] = df_train['reviews'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ooD12xKdxcSc",
    "outputId": "9c1db9d4-88c8-4bb2-a5cc-beabb1b6095a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-65c491d1-6e2c-4a74-892b-f94612a6a50b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>story man unnatural feeling pig start opening ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>0</td>\n",
       "      <td>airport start brand new luxury plane loaded va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>0</td>\n",
       "      <td>film lacked something put finger first charism...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry everyone know supposed art film wow hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>little parent took along theater see interior ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65c491d1-6e2c-4a74-892b-f94612a6a50b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-65c491d1-6e2c-4a74-892b-f94612a6a50b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-65c491d1-6e2c-4a74-892b-f94612a6a50b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                             reviews  sentiment  \\\n",
       "0  Story of a man who has unnatural feelings for ...          0   \n",
       "1  Airport '77 starts as a brand new luxury 747 p...          0   \n",
       "2  This film lacked something I couldn't put my f...          0   \n",
       "3  Sorry everyone,,, I know this is supposed to b...          0   \n",
       "4  When I was little my parents took me along to ...          0   \n",
       "\n",
       "                                       clean_reviews  \n",
       "0  story man unnatural feeling pig start opening ...  \n",
       "1  airport start brand new luxury plane loaded va...  \n",
       "2  film lacked something put finger first charism...  \n",
       "3  sorry everyone know supposed art film wow hand...  \n",
       "4  little parent took along theater see interior ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dq3PIXUMxcSc",
    "outputId": "f2747568-f7b2-4150-e04c-971b97b8c300"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-681b20c3b033>:12: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts = df_train['reviews'].apply(preprocess)\n",
    "type(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "K8-facUkxcSc"
   },
   "outputs": [],
   "source": [
    "train_texts = train_texts.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSpfT2N_xcSc",
    "outputId": "ca349074-7d88-4aa1-b43e-bac5f4b7f802"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I applied my preprocessing function on the reviews column of df_train, but realised that it was still in a series. I then converted it into a list, to be able to then tokenize the list (in the next part)\n",
    "\n",
    "I repeated this for the test data below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-X4yz9fxcSd"
   },
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "muKoj1IDxcSd"
   },
   "outputs": [],
   "source": [
    "df_test['reviews'] = df_test['reviews'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvVmkGwVxcSd",
    "outputId": "0eb8f41b-995d-45ea-f4e3-2165a6810a17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-681b20c3b033>:12: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "test_texts = df_test['reviews'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JspBR-W4xcSd",
    "outputId": "765b5692-b070-4454-f708-eccf96701c66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "rNRpMkL8xcSd"
   },
   "outputs": [],
   "source": [
    "test_texts = test_texts.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJ2jFs5kxcSd",
    "outputId": "61bf637e-446a-433e-afa6-d8093802f262"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "TbP2IVO8xcSd"
   },
   "outputs": [],
   "source": [
    "### uncomment the following if you fail the cleaning\n",
    "# train_texts = df_train.reviews.apply(lambda x: str(x)).tolist()\n",
    "# test_texts = df_test.reviews.apply(lambda x: str(x)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "dPqnfpSJxcSe"
   },
   "outputs": [],
   "source": [
    "train_labels = df_train.sentiment.tolist()\n",
    "test_labels = df_test.sentiment.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmifkoA8b5_N"
   },
   "source": [
    "# Tokenization of sentences using keras Tokenizer\n",
    "\n",
    "In keras, unlike pytorch, the Tokenizer not only splits the sentence into words but also convert words into their ids.<br>\n",
    "AS we have mentioned in class, keras is a high level layer on top of tensoflow implemented to allow novice DL users (more precisely traditional ML users) to develop DL models. <br>\n",
    "\n",
    "**Remember**, the pre-processing is learnt by looking at the train dataset only to garantee **no data leakage**, and it is applied on both datasets. \n",
    "&rarr; we fit the tokenizer on training data, then use it to tokenize both datasets. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhhqM0Jdd7fs",
    "outputId": "619131a5-556d-42fc-d997-787871aaebd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 129209 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "#Vectorize these text samples into a 2D integer tensor using Keras Tokenizer \n",
    "# \n",
    "MAX_NUM_WORDS = 20000 \n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS) \n",
    "tokenizer.fit_on_texts(train_texts) \n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts) #Converting text to a vector of word indexes \n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts) \n",
    "word_index = tokenizer.word_index \n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the code:\n",
    "\n",
    "- MAX_NUM_WORDS = 20000: Here, we are setting the maximum number of words that will be included in the tokenizer's vocabulary (20000)\n",
    "- tokenizer = Tokenizer(num_words=MAX_NUM_WORDS): Here we are creating a new Tokenizer object with the specified maximum number of words.\n",
    "- tokenizer.fit_on_texts(train_texts): Then we update tokenizer's vocabulary based by fitting our text in the train_texts list. \n",
    "- train_sequences = tokenizer.texts_to_sequences(train_texts): This will convert each text sample in the train_texts list into a sequence of integers, where each integer represents the index of a word in the tokenizer's vocabulary. (The resulting sequences are stored in a 2D integer tensor)\n",
    "- test_sequences = tokenizer.texts_to_sequences(test_texts): Same as the above, but for the test_set list\n",
    "- word_index = tokenizer.word_index: This maps words to their assigned integer indexes from the tokenizer. The word_index is a dictionary where the keys are the words in the vocabulary, and the values are their assigned integer indexes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDDSfEjVWdp2",
    "outputId": "349bc6d9-3883-4b0d-824f-1c05bfbaa01d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 51,\n",
       " 6784,\n",
       " 325,\n",
       " 3090,\n",
       " 143,\n",
       " 526,\n",
       " 16,\n",
       " 1196,\n",
       " 324,\n",
       " 1635,\n",
       " 100,\n",
       " 9545,\n",
       " 6693,\n",
       " 163,\n",
       " 578,\n",
       " 1959,\n",
       " 997,\n",
       " 2709,\n",
       " 797,\n",
       " 13661,\n",
       " 1529,\n",
       " 408,\n",
       " 536,\n",
       " 1635,\n",
       " 129,\n",
       " 5,\n",
       " 668,\n",
       " 1140,\n",
       " 734,\n",
       " 162,\n",
       " 1371,\n",
       " 10,\n",
       " 916,\n",
       " 578,\n",
       " 550,\n",
       " 12239,\n",
       " 296,\n",
       " 11,\n",
       " 12,\n",
       " 1651,\n",
       " 204,\n",
       " 669,\n",
       " 736,\n",
       " 9311,\n",
       " 1561,\n",
       " 452,\n",
       " 52,\n",
       " 141,\n",
       " 29,\n",
       " 6,\n",
       " 525,\n",
       " 597,\n",
       " 22,\n",
       " 597,\n",
       " 102,\n",
       " 3181,\n",
       " 11474,\n",
       " 14844,\n",
       " 7480,\n",
       " 38,\n",
       " 3182]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gp92C_BtxcSe"
   },
   "source": [
    "Since we are dealing with a classical ML/DL model, input dimension should always be fixed. <br>\n",
    "As in a traditional ML model, the number of attributes/features/columns should be fixed, in a DL model, the input dimension should be fixed as well. <br>\n",
    "In our case, the input features are sentences i.e. list of words. In order to make sure that the input has a fixed size, i.e. the sentences having the same size, we will need to fix a max length (MAX_LEN) parameter, which is the maximum number of words composing a sentence. <br>\n",
    "You might ask yourselves, But every sentence has a different set of words, shouldn't we create an input size that is equal to the number of unique words in our corpus? <br>\n",
    "The answer is No, because, we will never deal with words, we will deal with embeddings such that all words are embedded with vectors having the same dimension $d$ &rarr; every sentence of our corpus will be transformed into an input of size MAX_LEN $\\times d$ &rarr; our input will have the same size. <br>\n",
    "Thus: <br>\n",
    "- sentences with number of words > than MAX_LEN will be truncated; we chose a post truncating i.e., the first MAX_LEN are retained and the remaining words are removed. \n",
    "- sentences with number of words < than MAX_LEN will be padded; we chose a post padding i.e., the 0 id will be added after the ids of the words present in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "_e0V1-bBb5_d"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 1000\n",
    "trainvalid_data = pad_sequences(sequences=train_sequences, maxlen=MAX_LEN, padding='post', truncating='post', value=0.0)\n",
    "test_data = pad_sequences(sequences=test_sequences, maxlen=MAX_LEN, padding='post', truncating='post', value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZAyUtfVxcSf",
    "outputId": "94f1cbd6-79fd-40c8-ae3f-68af123635c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    8,    51,  6784,   325,  3090,   143,   526,    16,  1196,\n",
       "          324,  1635,   100,  9545,  6693,   163,   578,  1959,   997,\n",
       "         2709,   797, 13661,  1529,   408,   536,  1635,   129,     5,\n",
       "          668,  1140,   734,   162,  1371,    10,   916,   578,   550,\n",
       "        12239,   296,    11,    12,  1651,   204,   669,   736,  9311,\n",
       "         1561,   452,    52,   141,    29,     6,   525,   597,    22,\n",
       "          597,   102,  3181, 11474, 14844,  7480,    38,  3182,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0], dtype=int32),\n",
       " array([  291, 10709,  3028,     1,   144,  1080,  1549,  1116,  1196,\n",
       "         1755,  1883,   312,   310,     7,    78,   808,  3582,     7,\n",
       "         1554,   314,   273,  1467,    17,   217,     5,   310,     7,\n",
       "           14,   310,  8406, 19524, 11753, 14628,   188,    49,   134,\n",
       "           29,   113,    52,   173,   244,    98,    25,  1321,  3582,\n",
       "         4825,   623,  1653, 10709,   347,    18,   398,   269,    24,\n",
       "           83,  3622, 10709,   165,    78,   808,   481, 14628,  2486,\n",
       "           47,  2362, 13815, 11983,  1109,   179,    28,   195,  1453,\n",
       "          224,   308,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0], dtype=int32))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainvalid_data[0], test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding this part:\n",
    "\n",
    "Why are there so many zeros in the array?\n",
    "\n",
    "There are many zeros in the trainvalid_data array because it represents a sequence of integers that has been padded with zeros so that it has a length of MAX_LEN. If a position in the sequence did not have a word or token that reaches \"max_length\", the original text data are filled with zeros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WuQkfXExcSf"
   },
   "source": [
    "# Converting the target into a categorical tensor variable for DL model training\n",
    "Keras implements the command ``to_categorical``, it transforms each label into a one-hot encode array of dimension = unique number of categories and sets the value 1 on the index i if the data sample belongs to the category i else 0. With to categorical, if an input belongs to several categories at a time, the label would contain several 1. <br>\n",
    "Here there is 2 catgories: neg and pos &rarr; the dimension is 2. <br>\n",
    "Example: the target of a review with a pos review is converted with ``to_categorical`` to an ``array([0,1])``, while the target of a review with a neg review is converted with ``to_categorical`` to an ``array([1,0])``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "lJ_i8YubxcSf"
   },
   "outputs": [],
   "source": [
    "trainvalid_labels = to_categorical(np.asarray(train_labels))\n",
    "test_labels = to_categorical(np.asarray(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YN-m73eWxcSf",
    "outputId": "f2d107c4-3da1-460c-fb6b-ed69e46c6b99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, array([0., 1.], dtype=float32))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[12500] , trainvalid_labels[12500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-duwjaGxcSg"
   },
   "source": [
    "# Split the training data into a training set and a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "K6ym4xFmxcSg"
   },
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.2\n",
    "indices = np.arange(trainvalid_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "trainvalid_data = trainvalid_data[indices]\n",
    "trainvalid_labels = trainvalid_labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * trainvalid_data.shape[0])\n",
    "x_train = trainvalid_data[:-num_validation_samples]\n",
    "y_train = trainvalid_labels[:-num_validation_samples]\n",
    "x_val = trainvalid_data[-num_validation_samples:]\n",
    "y_val = trainvalid_labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JaygHsfSp2j",
    "outputId": "7d01a40f-9506-4aae-9aeb-697094532a8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 1000), (20000, 2))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vHQs7sxxcSg"
   },
   "source": [
    "# Convert the token ids into embedding vectors\n",
    "1. Extract embeddings from glove.6B.100d.txt\n",
    "2. Convert the words in the dataset into embeddings using the dictionary from step 1\n",
    "3. Create the embedding layer for keras; this will be the first layer of our DL model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Extract embeddings from glove.6B.100d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gPDG_VNu_ELC",
    "outputId": "2efbc31f-e4d9-462d-8b4d-7c9201711087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix.\n",
      "Found 400000 word vectors in Glove embeddings.\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "print('Preparing embedding matrix.')\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors in Glove embeddings.' % len(embeddings_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Convert the words in the dataset into embeddings using the dictionary from step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "J9puF9eM_UlR"
   },
   "outputs": [],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create the embedding layer for keras; this will be the first layer of our DL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKasBWVnpFqe",
    "outputId": "4ca42a0b-44fd-4ced-8da5-41bd49e2fb2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing of embedding matrix is done\n"
     ]
    }
   ],
   "source": [
    "# load these pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed during training\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_LEN,\n",
    "                            trainable=False)\n",
    "print(\"Preparing of embedding matrix is done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEastnX8gdxR"
   },
   "source": [
    "# Training and evaluating the DL model\n",
    "We will test 3 DL models:\n",
    "- 1D CNN-based architecture\n",
    "- LSTM-based architecture\n",
    "- Transformer-based architecture (to do it on your own)\n",
    "\n",
    "### 1D CNN Model with pre-trained embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What I changed in the code:\n",
    "\n",
    "- Here, label_index had not been previously defined, so I created a new variable called num_classes that represents the number of unique labels in the training dataset - in order to complete the model\n",
    "- I added this to both CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTY-4K-Ob5_t",
    "outputId": "6f735287-5342-46f2-d7cf-267b8032c1b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define a 1D CNN model.\n",
      "157/157 [==============================] - 16s 31ms/step - loss: 0.6226 - acc: 0.6586 - val_loss: 0.5741 - val_acc: 0.6853\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.5756 - acc: 0.6956\n",
      "Test accuracy with CNN: 0.6955878138542175\n"
     ]
    }
   ],
   "source": [
    "# Define the number of classes\n",
    "num_classes = len(np.unique(train_labels))\n",
    "\n",
    "print('Define a 1D CNN model.')\n",
    "\n",
    "cnnmodel = Sequential()\n",
    "cnnmodel.add(\\)\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(MaxPooling1D(5))\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(MaxPooling1D(5))\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(GlobalMaxPooling1D())\n",
    "cnnmodel.add(Dense(128, activation='relu'))\n",
    "cnnmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "cnnmodel.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "#Train the model. Tune to validation set. \n",
    "cnnmodel.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1, validation_data=(x_val, y_val))\n",
    "#Evaluate on test set:\n",
    "score, acc = cnnmodel.evaluate(test_data, test_labels)\n",
    "print('Test accuracy with CNN:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdDj2FJzgi_W"
   },
   "source": [
    "### 1D CNN model with training your own embedding\n",
    "The only difference here is that the embedding layer we created ``embedding_layer`` using the pre-trained glove embeddings is no longer used here. We initialize an ambedding layer with randomly initialized weights ``Embedding(MAX_NUM_WORDS, 128)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zI0bISwRb5_w",
    "outputId": "a781922b-eaa4-43f9-d2b5-5280031ce8ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining and training a CNN model, training embedding layer on the fly instead of using pre-trained embeddings\n",
      "157/157 [==============================] - 28s 168ms/step - loss: 0.6902 - acc: 0.5199 - val_loss: 0.6466 - val_acc: 0.5579\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.6421 - acc: 0.5672\n",
      "Test accuracy with CNN: 0.5672227144241333\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(train_labels))\n",
    "\n",
    "print(\"Defining and training a CNN model, training embedding layer on the fly instead of using pre-trained embeddings\")\n",
    "cnnmodel = Sequential()\n",
    "cnnmodel.add(Embedding(MAX_NUM_WORDS, 128))\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(MaxPooling1D(5))\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(MaxPooling1D(5))\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(GlobalMaxPooling1D())\n",
    "cnnmodel.add(Dense(128, activation='relu'))\n",
    "cnnmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "cnnmodel.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "#Train the model. Tune to validation set. \n",
    "cnnmodel.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1, validation_data=(x_val, y_val))\n",
    "#Evaluate on test set:\n",
    "score, acc = cnnmodel.evaluate(test_data, test_labels)\n",
    "print('Test accuracy with CNN:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GwhXpmSgt4H"
   },
   "source": [
    "### LSTM Model with training your own embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SvBt2Brib5_4",
    "outputId": "d68cd826-f041-4df0-da3e-f44ce594b766"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining and training an LSTM model, training embedding layer on the fly\n",
      "Training the RNN\n",
      "625/625 [==============================] - 1441s 2s/step - loss: 0.6933 - accuracy: 0.5027 - val_loss: 0.6931 - val_accuracy: 0.5057\n",
      "782/782 [==============================] - 212s 271ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Test accuracy with RNN: 0.5000200271606445\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining and training an LSTM model, training embedding layer on the fly\")\n",
    "\n",
    "#model\n",
    "rnnmodel = Sequential()\n",
    "rnnmodel.add(Embedding(MAX_NUM_WORDS, 128))\n",
    "rnnmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "rnnmodel.add(Dense(2, activation='sigmoid'))\n",
    "rnnmodel.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print('Training the RNN')\n",
    "\n",
    "rnnmodel.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=1,\n",
    "          validation_data=(x_val, y_val))\n",
    "score, acc = rnnmodel.evaluate(test_data, test_labels,\n",
    "                            batch_size=32)\n",
    "print('Test accuracy with RNN:', acc)\n",
    "#Test accuracy with RNN: 0.82998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJYzsZFSg9z-"
   },
   "source": [
    "### LSTM Model using pre-trained Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eymx0IyCb5_-",
    "outputId": "bb9ec69e-19f7-4e79-a4e4-ee7f4b051a56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining and training an LSTM model, using pre-trained embedding layer\n",
      "Training the RNN\n",
      "625/625 [==============================] - 1068s 2s/step - loss: 0.6933 - accuracy: 0.4942 - val_loss: 0.6931 - val_accuracy: 0.5057\n",
      "782/782 [==============================] - 224s 286ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Test accuracy with RNN: 0.5000200271606445\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining and training an LSTM model, using pre-trained embedding layer\")\n",
    "\n",
    "rnnmodel2 = Sequential()\n",
    "rnnmodel2.add(embedding_layer)\n",
    "rnnmodel2.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "rnnmodel2.add(Dense(2, activation='sigmoid'))\n",
    "rnnmodel2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print('Training the RNN')\n",
    "\n",
    "rnnmodel2.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=1,\n",
    "          validation_data=(x_val, y_val))\n",
    "score, acc = rnnmodel2.evaluate(test_data, test_labels,\n",
    "                            batch_size=32)\n",
    "print('Test accuracy with RNN:', acc)\n",
    "#Test accuracy with RNN: 0.793"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the LSTM results: \n",
    "\n",
    "In both cases, training our own embedding and using our pre-trained embedding layer, the LSTM models only accuracy of 50% on the test data, which means that it is essntially just randomly guessing the output. This suggests that the model is not learning patterns from the training data and is instead making random predictions. The loss values (0.69) also seem to be high, which indicates that the model is not able to fit the data well.\n",
    "\n",
    "Perhaps the model needs more training epochs or a more complex architecture to learn the dataa better. Alternatively, the data may need further preprocessing or feature engineering to improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbjGhCvQxcSi"
   },
   "source": [
    "### Transformer Model \n",
    "Refer to the [keras tutorial](https://keras.io/examples/nlp/text_classification_with_transformer/) to implement and evaluate your model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpAW1DZwEbR3"
   },
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "I3MpB9nKp50i"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtV5GBtuEd4f"
   },
   "source": [
    "**Implement a Transformer block as a layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "qvTz8LvIEmJq"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGXcvSEtEwz1"
   },
   "source": [
    "**Implement embedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "mlZo8WuYE1ms"
   },
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TJThvKKE5kd"
   },
   "source": [
    "**Create classifier model using transformer layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "DUxPx4XhE3ou"
   },
   "outputs": [],
   "source": [
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "#embedding layer already defined\n",
    "inputs = layers.Input(shape=(MAX_LEN,))\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(EMBEDDING_DIM, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewLxQk2cFHfO"
   },
   "source": [
    "**Train and Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dN3ofz-1SiJa",
    "outputId": "3f1df19f-494c-42b8-e0f3-3b7926493651"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 1000), (20000, 2))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53eOMzQzFHuy",
    "outputId": "a0f0c8a2-f314-4c8c-8e27-02c2beba793d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "313/313 [==============================] - 45s 130ms/step - loss: 0.5116 - accuracy: 0.7430 - val_loss: 0.3677 - val_accuracy: 0.8388\n",
      "Epoch 2/2\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 0.3919 - accuracy: 0.8340 - val_loss: 0.3547 - val_accuracy: 0.8466\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss= \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=64, epochs=2, validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbvlUUIzUS-w"
   },
   "source": [
    "**Evaluate on the Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQ9g0rY-SZd5",
    "outputId": "88dd5df0-b5d5-4e7a-fa24-74e67970340f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 4s 24ms/step - loss: 0.3547 - accuracy: 0.8466\n",
      "Test loss: 0.3547024428844452\n",
      "Test accuracy: 0.846569299697876\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_val, y_val)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUI-8wQcU9VK"
   },
   "source": [
    "#### Understanding the Transformer results:\n",
    "\n",
    "We can see from our results (on the training set) that during the first epoch, the model achieved a training accuracy of 74.3% and a validation accuracy of 83.8%, and then in the second epoch, it achieved a training accuracy of 83.4% and a validation accuracy of 84.7%. This indicates that the model is improving in accuracy as it trains.\n",
    "\n",
    "I then evaluated my model on the test set. Here, the model achieved a loss of 0.355 and an accuracy of 84.7%, which is very close to the validation accuracy achieved during training. This suggests that the model has generalized well to unseen data.\n",
    "\n",
    "Overall, the transformer model seems to have performed well on this task, achieving a relatively high accuracy on both the training and testing sets.\n",
    "\n",
    "\n",
    "\n",
    "Overall, we can also conclude baased on the resutls, that the transformer was our best performing model, to predict sentiment based on movie reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
